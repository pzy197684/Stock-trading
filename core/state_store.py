# core/state_store.py
# åŠŸèƒ½ï¼šé‡æ„åçš„çŠ¶æ€ç®¡ç†å™¨ï¼Œæ”¯æŒå¤šè´¦å·éš”ç¦»ã€JSONåºåˆ—åŒ–ã€UIå‹å¥½æ ¼å¼
import os
import json
import time
from datetime import datetime, timezone
from tempfile import NamedTemporaryFile
from typing import Optional, Dict, Any, List
from pathlib import Path
from core.logger import logger
from core.domain.models import AccountState, PositionState, Metrics

class StateManager:
    """
    çŠ¶æ€ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. å¤šè´¦å·çŠ¶æ€éš”ç¦»
    2. JSONæ ¼å¼å­˜å‚¨ï¼ŒUIå‹å¥½
    3. åŸå­åŒ–æ›´æ–°æ“ä½œ
    4. çŠ¶æ€å¿«ç…§åŠŸèƒ½
    5. çŠ¶æ€å†å²è®°å½•
    6. æ•°æ®éªŒè¯å’Œè¿ç§»
    """
    
    def __init__(self, base_path: Optional[str] = None):
        self.base_path = Path(base_path) if base_path else self._get_default_base_path()
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # çŠ¶æ€ç¼“å­˜
        self._state_cache: Dict[str, AccountState] = {}
        
        # æ–‡ä»¶ä¿®æ”¹æ—¶é—´ç¼“å­˜ï¼ˆç”¨äºæ£€æµ‹å¤–éƒ¨ä¿®æ”¹ï¼‰
        self._file_mtimes: Dict[str, float] = {}
        
    def _get_default_base_path(self) -> Path:
        """è·å–é»˜è®¤çŠ¶æ€å­˜å‚¨è·¯å¾„"""
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
        env_path = os.environ.get("STATE_DIR")
        if env_path:
            return Path(env_path)
        
        # è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent  # ä» core/state_store.py å‘ä¸Šä¸¤çº§
        return project_root / "state"
    
    def get_account_path(self, account: str) -> Path:
        """è·å–è´¦å·çŠ¶æ€ç›®å½•è·¯å¾„"""
        account = account.upper()
        account_path = self.base_path / account
        account_path.mkdir(parents=True, exist_ok=True)
        return account_path
    
    def get_state_file_path(self, account: str) -> Path:
        """è·å–è´¦å·çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
        return self.get_account_path(account) / "state.json"
    
    def get_history_path(self, account: str) -> Path:
        """è·å–è´¦å·å†å²è®°å½•ç›®å½•"""
        history_path = self.get_account_path(account) / "history"
        history_path.mkdir(parents=True, exist_ok=True)
        return history_path
    
    def create_default_state(self) -> AccountState:
        """åˆ›å»ºé»˜è®¤çŠ¶æ€"""
        return AccountState(
            long=PositionState(),
            short=PositionState(),
            metrics=Metrics(),
            pause_until=None,
            schema_hydrated={},
            backfill_done={},
            # æ–°å¢UIå‹å¥½å­—æ®µ
            metadata={
                "created_at": self._get_iso_timestamp(),
                "updated_at": self._get_iso_timestamp(),
                "version": "2.0.0",
                "account": "",
                "platform": "",
                "strategy": "",
                "status": "initialized"
            }
        )
    
    def load_state(self, account: str, use_cache: bool = True) -> AccountState:
        """
        åŠ è½½è´¦å·çŠ¶æ€
        
        Args:
            account: è´¦å·å
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            è´¦å·çŠ¶æ€å¯¹è±¡
        """
        account = account.upper()
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and account in self._state_cache:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å¤–éƒ¨ä¿®æ”¹
            if not self._is_file_modified(account):
                return self._state_cache[account]
        
        state_file = self.get_state_file_path(account)
        
        if not state_file.exists():
            logger.log_info(f"ğŸ“ Creating new state file for account: {account}")
            state = self.create_default_state()
            state.metadata["account"] = account
            self.save_state(account, state)
            return state
        
        try:
            with open(state_file, 'r', encoding='utf-8-sig') as f:
                state_dict = json.load(f)
            
            # è®°å½•æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            self._file_mtimes[account] = state_file.stat().st_mtime
            
            # æ•°æ®è¿ç§»å’ŒéªŒè¯
            state_dict = self._migrate_and_validate(state_dict, account)
            
            # ååºåˆ—åŒ–ä¸ºAccountStateå¯¹è±¡
            state = self._dict_to_account_state(state_dict)
            
            # ç¼“å­˜çŠ¶æ€
            if use_cache:
                self._state_cache[account] = state
            
            logger.log_info(f"âœ… Loaded state for account: {account}")
            return state
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to load state for account {account}: {e}")
            # å¤‡ä»½æŸåçš„æ–‡ä»¶
            self._backup_corrupted_file(account)
            # è¿”å›é»˜è®¤çŠ¶æ€
            state = self.create_default_state()
            state.metadata["account"] = account
            return state
    
    def save_state(self, account: str, state: AccountState, create_snapshot: bool = False) -> bool:
        """
        ä¿å­˜è´¦å·çŠ¶æ€
        
        Args:
            account: è´¦å·å
            state: çŠ¶æ€å¯¹è±¡
            create_snapshot: æ˜¯å¦åˆ›å»ºå¿«ç…§
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        account = account.upper()
        state_file = self.get_state_file_path(account)
        
        try:
            # æ›´æ–°metadata
            state.metadata["updated_at"] = self._get_iso_timestamp()
            state.metadata["account"] = account
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            state_dict = self._account_state_to_dict(state)
            
            # åŸå­å†™å…¥
            temp_file = state_file.parent / f".{state_file.name}.tmp"
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(state_dict, f, ensure_ascii=False, indent=2, default=self._json_serializer)
            
            # åŸå­æ›¿æ¢
            temp_file.replace(state_file)
            
            # æ›´æ–°ç¼“å­˜
            self._state_cache[account] = state
            self._file_mtimes[account] = state_file.stat().st_mtime
            
            # åˆ›å»ºå¿«ç…§ï¼ˆå¯é€‰ï¼‰
            if create_snapshot:
                self._create_snapshot(account, state_dict)
            
            logger.log_info(f"ğŸ’¾ Saved state for account: {account}")
            return True
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to save state for account {account}: {e}")
            return False
    
    def update_state_bulk(self, account: str, updates: Dict[str, Any], 
                         create_snapshot: bool = False) -> bool:
        """
        æ‰¹é‡æ›´æ–°çŠ¶æ€å­—æ®µ
        
        Args:
            account: è´¦å·å
            updates: æ›´æ–°å­—æ®µå­—å…¸ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„å¦‚ "long.qty"
            create_snapshot: æ˜¯å¦åˆ›å»ºå¿«ç…§
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            state = self.load_state(account)
            
            # åº”ç”¨æ›´æ–°
            for key_path, value in updates.items():
                self._update_nested_field(state, key_path, value)
            
            # æ›´æ–°æ—¶é—´æˆ³
            state.metadata["updated_at"] = self._get_iso_timestamp()
            
            # ä¿å­˜çŠ¶æ€
            return self.save_state(account, state, create_snapshot)
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to bulk update state for account {account}: {e}")
            return False
    
    def get_state_summary(self, account: str) -> Dict[str, Any]:
        """
        è·å–çŠ¶æ€æ‘˜è¦ï¼ˆUIå‹å¥½æ ¼å¼ï¼‰
        
        Args:
            account: è´¦å·å
            
        Returns:
            çŠ¶æ€æ‘˜è¦å­—å…¸
        """
        try:
            state = self.load_state(account)
            
            return {
                "account": account,
                "status": state.metadata.get("status", "unknown"),
                "platform": state.metadata.get("platform", ""),
                "strategy": state.metadata.get("strategy", ""),
                "updated_at": state.metadata.get("updated_at", ""),
                "positions": {
                    "long": {
                        "qty": state.long.qty,
                        "avg_price": state.long.avg_price,
                        "unrealized_pnl": 0.0,  # å¯ç”±å¤–éƒ¨è®¡ç®—å¡«å…¥
                        "add_times": state.long.add_times,
                        "hedge_locked": state.long.hedge_locked,
                        "hedge_stop": state.long.hedge_stop
                    },
                    "short": {
                        "qty": state.short.qty,
                        "avg_price": state.short.avg_price,
                        "unrealized_pnl": 0.0,  # å¯ç”±å¤–éƒ¨è®¡ç®—å¡«å…¥
                        "add_times": state.short.add_times,
                        "hedge_locked": state.short.hedge_locked,
                        "hedge_stop": state.short.hedge_stop
                    }
                },
                "metrics": {
                    "nv_prev": state.metrics.nv_prev,
                    "last_snapshot_date": state.metrics.last_snapshot_date
                },
                "pause_until": state.pause_until,
                "file_path": str(self.get_state_file_path(account))
            }
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to get state summary for account {account}: {e}")
            return {
                "account": account,
                "status": "error",
                "error": str(e)
            }
    
    def list_accounts(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰è´¦å·"""
        accounts = []
        try:
            for account_dir in self.base_path.iterdir():
                if account_dir.is_dir() and (account_dir / "state.json").exists():
                    accounts.append(account_dir.name)
            return sorted(accounts)
        except Exception as e:
            logger.log_error(f"âŒ Failed to list accounts: {e}")
            return []
    
    def get_all_accounts_summary(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è´¦å·çš„çŠ¶æ€æ‘˜è¦"""
        summaries = []
        for account in self.list_accounts():
            summaries.append(self.get_state_summary(account))
        return summaries
    
    def delete_account_state(self, account: str, create_backup: bool = True) -> bool:
        """
        åˆ é™¤è´¦å·çŠ¶æ€
        
        Args:
            account: è´¦å·å
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            account = account.upper()
            account_path = self.get_account_path(account)
            
            if not account_path.exists():
                logger.log_warning(f"âš ï¸  Account state not found: {account}")
                return True
            
            # åˆ›å»ºå¤‡ä»½
            if create_backup:
                backup_name = f"deleted_{account}_{int(time.time())}"
                backup_path = self.base_path / "backups" / backup_name
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                # ç§»åŠ¨æ•´ä¸ªè´¦å·ç›®å½•åˆ°å¤‡ä»½ä½ç½®
                account_path.rename(backup_path)
                logger.log_info(f"ğŸ“¦ Backed up account {account} to {backup_path}")
            else:
                # ç›´æ¥åˆ é™¤
                import shutil
                shutil.rmtree(account_path)
            
            # æ¸…ç†ç¼“å­˜
            self._state_cache.pop(account, None)
            self._file_mtimes.pop(account, None)
            
            logger.log_info(f"ğŸ—‘ï¸  Deleted state for account: {account}")
            return True
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to delete state for account {account}: {e}")
            return False
    
    # ç§æœ‰è¾…åŠ©æ–¹æ³•
    def _get_iso_timestamp(self) -> str:
        """è·å–ISOæ ¼å¼çš„æ—¶é—´æˆ³"""
        return datetime.now(timezone.utc).isoformat()
    
    def _is_file_modified(self, account: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å¤–éƒ¨ä¿®æ”¹"""
        try:
            state_file = self.get_state_file_path(account)
            if not state_file.exists():
                return True
            
            current_mtime = state_file.stat().st_mtime
            cached_mtime = self._file_mtimes.get(account, 0)
            return current_mtime > cached_mtime
        except Exception:
            return True
    
    def _migrate_and_validate(self, state_dict: Dict[str, Any], account: str) -> Dict[str, Any]:
        """æ•°æ®è¿ç§»å’ŒéªŒè¯"""
        # 1. è¿ç§»æ—§ç‰ˆå­—æ®µ
        migrated = False
        for side in ("long", "short"):
            if side not in state_dict or not isinstance(state_dict[side], dict):
                state_dict[side] = {}
            
            # ç¡®ä¿æ–°å­—æ®µå­˜åœ¨
            state_dict[side].setdefault("hedge_locked", False)
            state_dict[side].setdefault("hedge_stop", False)
            state_dict[side].setdefault("locked_profit", 0)
        
        # å¤„ç†é¡¶å±‚æ—§å­—æ®µ
        if "hedge_locked" in state_dict:
            for side in ("long", "short"):
                if not state_dict[side].get("hedge_locked"):
                    state_dict[side]["hedge_locked"] = state_dict["hedge_locked"]
            state_dict.pop("hedge_locked")
            migrated = True
        
        if "locked_profit" in state_dict:
            for side in ("long", "short"):
                if not state_dict[side].get("locked_profit"):
                    state_dict[side]["locked_profit"] = state_dict["locked_profit"]
            state_dict.pop("locked_profit")
            migrated = True
        
        # 2. å­—æ®µè¡¥å…¨
        for side in ("long", "short"):
            d = state_dict[side]
            d.setdefault("qty", 0)
            d.setdefault("avg_price", 0)
            d.setdefault("add_times", 0)
            d.setdefault("round", 0)
            d.setdefault("last_qty", 0)
            d.setdefault("opposite_qty", 0)
            d.setdefault("last_entry_price", d.get("avg_price", 0) or 0)
            d.setdefault("last_fill_price", d.get("avg_price", 0) or 0)
            d.setdefault("last_fill_ts", 0)
            d.setdefault("last_open_ts", 0)
            d.setdefault("fast_add_paused_until", 0)
            d.setdefault("cooldown_until", 0)
            d.setdefault("last_add_time", None)
        
        # 3. é¡¶çº§å­—æ®µè¡¥å…¨
        state_dict.setdefault("schema_hydrated", {})
        state_dict.setdefault("backfill_done", {})
        state_dict.setdefault("pause_until", None)
        
        # 4. metricsè¡¥å…¨
        m = state_dict.setdefault("metrics", {})
        m.setdefault("nv_prev", 0.0)
        m.setdefault("last_snapshot_date", "")
        
        # 5. metadataè¡¥å…¨
        meta = state_dict.setdefault("metadata", {})
        current_time = self._get_iso_timestamp()
        meta.setdefault("created_at", current_time)
        meta.setdefault("updated_at", current_time)
        meta.setdefault("version", "2.0.0")
        meta.setdefault("account", account)
        meta.setdefault("platform", "")
        meta.setdefault("strategy", "")
        meta.setdefault("status", "initialized")
        
        if migrated:
            logger.log_info(f"âœ… Migrated legacy fields for account: {account}")
        
        return state_dict
    
    def _dict_to_account_state(self, state_dict: Dict[str, Any]) -> AccountState:
        """å°†å­—å…¸è½¬æ¢ä¸ºAccountStateå¯¹è±¡"""
        return AccountState(
            long=PositionState(**state_dict["long"]),
            short=PositionState(**state_dict["short"]),
            metrics=Metrics(**state_dict["metrics"]),
            pause_until=state_dict.get("pause_until"),
            schema_hydrated=state_dict.get("schema_hydrated", {}),
            backfill_done=state_dict.get("backfill_done", {}),
            metadata=state_dict.get("metadata", {})
        )
    
    def _account_state_to_dict(self, state: AccountState) -> Dict[str, Any]:
        """å°†AccountStateå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "long": self._position_state_to_dict(state.long),
            "short": self._position_state_to_dict(state.short),
            "metrics": {
                "nv_prev": state.metrics.nv_prev,
                "last_snapshot_date": state.metrics.last_snapshot_date
            },
            "pause_until": state.pause_until,
            "schema_hydrated": state.schema_hydrated,
            "backfill_done": state.backfill_done,
            "metadata": state.metadata
        }
    
    def _position_state_to_dict(self, pos: PositionState) -> Dict[str, Any]:
        """å°†PositionStateå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "qty": pos.qty,
            "avg_price": pos.avg_price,
            "add_times": pos.add_times,
            "last_add_time": pos.last_add_time,
            "hedge_locked": pos.hedge_locked,
            "hedge_stop": pos.hedge_stop,
            "locked_profit": pos.locked_profit,
            "round": pos.round,
            "last_qty": pos.last_qty,
            "opposite_qty": pos.opposite_qty,
            "last_entry_price": pos.last_entry_price,
            "last_fill_price": pos.last_fill_price,
            "last_fill_ts": pos.last_fill_ts,
            "last_open_ts": pos.last_open_ts,
            "fast_add_paused_until": pos.fast_add_paused_until,
            "cooldown_until": pos.cooldown_until
        }
    
    def _json_serializer(self, obj) -> Any:
        """è‡ªå®šä¹‰JSONåºåˆ—åŒ–å™¨"""
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        return str(obj)
    
    def _update_nested_field(self, state: AccountState, key_path: str, value: Any):
        """æ›´æ–°åµŒå¥—å­—æ®µ"""
        keys = key_path.split('.')
        current = state
        
        # å¯¼èˆªåˆ°ç›®æ ‡å¯¹è±¡
        for key in keys[:-1]:
            if hasattr(current, key):
                current = getattr(current, key)
            elif isinstance(current, dict) and key in current:
                current = current[key]
            else:
                raise ValueError(f"Invalid key path: {key_path}")
        
        # è®¾ç½®æœ€ç»ˆå€¼
        final_key = keys[-1]
        if hasattr(current, final_key):
            setattr(current, final_key, value)
        elif isinstance(current, dict):
            current[final_key] = value
        else:
            raise ValueError(f"Cannot set field: {key_path}")
    
    def _create_snapshot(self, account: str, state_dict: Dict[str, Any]):
        """åˆ›å»ºçŠ¶æ€å¿«ç…§"""
        try:
            history_path = self.get_history_path(account)
            timestamp = int(time.time())
            snapshot_file = history_path / f"snapshot_{timestamp}.json"
            
            with open(snapshot_file, 'w', encoding='utf-8') as f:
                json.dump(state_dict, f, ensure_ascii=False, indent=2, default=self._json_serializer)
            
            logger.log_info(f"ğŸ“¸ Created snapshot for account {account}: {snapshot_file.name}")
            
            # æ¸…ç†æ—§å¿«ç…§ï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
            self._cleanup_old_snapshots(account, keep_count=10)
            
        except Exception as e:
            logger.log_error(f"âŒ Failed to create snapshot for account {account}: {e}")
    
    def _cleanup_old_snapshots(self, account: str, keep_count: int = 10):
        """æ¸…ç†æ—§å¿«ç…§"""
        try:
            history_path = self.get_history_path(account)
            snapshots = list(history_path.glob("snapshot_*.json"))
            
            if len(snapshots) > keep_count:
                # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
                snapshots.sort(key=lambda f: f.stat().st_mtime, reverse=True)
                for old_snapshot in snapshots[keep_count:]:
                    old_snapshot.unlink()
                    logger.log_info(f"ğŸ—‘ï¸  Cleaned up old snapshot: {old_snapshot.name}")
                    
        except Exception as e:
            logger.log_error(f"âŒ Failed to cleanup old snapshots for account {account}: {e}")
    
    def _backup_corrupted_file(self, account: str):
        """å¤‡ä»½æŸåçš„çŠ¶æ€æ–‡ä»¶"""
        try:
            state_file = self.get_state_file_path(account)
            if state_file.exists():
                backup_dir = self.base_path / "corrupted_backups"
                backup_dir.mkdir(parents=True, exist_ok=True)
                
                timestamp = int(time.time())
                backup_file = backup_dir / f"{account}_corrupted_{timestamp}.json"
                
                state_file.rename(backup_file)
                logger.log_warning(f"âš ï¸  Backed up corrupted file: {backup_file}")
                
        except Exception as e:
            logger.log_error(f"âŒ Failed to backup corrupted file for account {account}: {e}")


# å‘åå…¼å®¹çš„å‡½æ•°æ¥å£
def load_state(account: Optional[str] = None) -> AccountState:
    """å‘åå…¼å®¹ï¼šåŠ è½½çŠ¶æ€"""
    account = account or os.environ.get("ACCOUNT", "BN1602")
    manager = StateManager()
    return manager.load_state(account)

def save_state(account: Optional[str], state: AccountState):
    """å‘åå…¼å®¹ï¼šä¿å­˜çŠ¶æ€"""
    if account is None:
        account = os.environ.get("ACCOUNT", "BN1602")
    manager = StateManager()
    manager.save_state(account, state)

def get_state_path(account: Optional[str] = None) -> str:
    """å‘åå…¼å®¹ï¼šè·å–çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
    account = account or os.environ.get("ACCOUNT", "BN1602")
    manager = StateManager()
    return str(manager.get_state_file_path(account))

# å…¨å±€çŠ¶æ€ç®¡ç†å™¨å®ä¾‹
_state_manager = None

def get_state_manager() -> StateManager:
    """è·å–å…¨å±€çŠ¶æ€ç®¡ç†å™¨å®ä¾‹"""
    global _state_manager
    if _state_manager is None:
        _state_manager = StateManager()
    return _state_manager
